{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lyric-pricing",
   "metadata": {
    "id": "lyric-pricing"
   },
   "source": [
    "# Week 09: Word Sense Disambiguation\n",
    "\n",
    "This week, we introduced a hot topic in Natural Language Proccessing: *Word Sense Disambiguation (WSD)* .  \n",
    "Many words in natural languages have ambiguous meanings. For example, the word *[party](https://dictionary.cambridge.org/dictionary/english/party)* can refer to 1) a social gathering (派對), 2) a political organization (政黨), or 3) an entity in law (當事人；⋯⋯方).  \n",
    "As a human, we can distinguish different meanings easily, but can a machine do the same? This is what WSD aims for.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-injury",
   "metadata": {
    "id": "mysterious-injury"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### tl; dr\n",
    "You have to \n",
    "1. preprocess the data\n",
    "2. (stage 1) generate a small training dataset from the given collocation seed,\n",
    "3. (stage 1) train a weak model on that small dataset,\n",
    "4. (stage 2) use the weak model to generate more labeled data, and\n",
    "5. (stage 2) train your final model\n",
    "6. Evaluate your model on testing data (requirement: accuracy > 0.7)\n",
    "\n",
    "### Concept\n",
    "\n",
    "In [Lesk's assumption](https://en.wikipedia.org/wiki/Lesk_algorithm), each word has only one sense when it appears in the same collocation.  \n",
    "For example, if *party* shows up with the word *court* (法庭), most likely the sense of this *party* is the 3rd one: an entity in law (當事人；⋯⋯方).  \n",
    "However, we are not implementing Lesk's algorithm this week. Instead, we will combine his assumption with [Yarowsky's](https://en.wikipedia.org/wiki/Yarowsky_algorithm) *bootstrap technique* .  \n",
    "\n",
    "You are given some pre-defined collocations, or called *seeds*, of the word *party*, along with which sense each collocation belongs to.  \n",
    "With the given seeds, you can generate a small set of labeled data by rule. Then with this small set, we can train a small model with limited accuracy.  \n",
    "The current classifier might not perform well on the whole dataset, sure, but it's already enough to generate more reliable labeled data. With the newly labeled training data, we can now train another sense-classification model with more robustness, which aims for the real WSD task.  \n",
    "This process, about training on smaller dataset, generating more data, and then improving the model itself, is called *[bootstrapping](https://www.mastersindatascience.org/learning/introduction-to-machine-learning-algorithms/bootstrapping/)* .  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7QH39jVBvHb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7QH39jVBvHb",
    "outputId": "f16b2e4c-5e1a-4719-c7d5-16b1af93ee06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n",
      "Downloading 1ekUZ1zGSs6UjM_jfmAOuzNCgcOyWdsyR into ./GoogleNews-vectors-negative300.bin.gz... Done.\n"
     ]
    }
   ],
   "source": [
    "!pip install googledrivedownloader\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1ekUZ1zGSs6UjM_jfmAOuzNCgcOyWdsyR',\n",
    "                                    dest_path='./GoogleNews-vectors-negative300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "j3Uq_yoTB3Yq",
   "metadata": {
    "id": "j3Uq_yoTB3Yq"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('GoogleNews-vectors-negative300.bin.gz', 'rb') as f_in:\n",
    "    with open('GoogleNews-vectors-negative300.bin', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-smart",
   "metadata": {
    "id": "resident-smart"
   },
   "source": [
    "<a name=\"I.-Data-preparation\"></a>\n",
    "## I. Data preparation\n",
    "\n",
    "First thing first. To make natural language understandable for machines, we have to transform sentences into embeddings.  \n",
    "So here are four things to do:\n",
    "\n",
    "1. load data\n",
    "2. preprocess the sentences\n",
    "3. transform sentences into embeddings\n",
    "4. pad the sentences to the same length\n",
    "\n",
    "To make the task simple and easy to understand, we will only work on a single word *party* .  \n",
    "Three senses of *party* is defined as below with their corresponding `sense id`s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "involved-cooper",
   "metadata": {
    "id": "involved-cooper"
   },
   "outputs": [],
   "source": [
    "SENSE = {\n",
    "    1: 'a social event at which a group of people meet to talk, eat, drink, dance, etc.', # 派對\n",
    "    2: 'an organization of people with particular political beliefs', # 政黨\n",
    "    3: 'a single entity which can be identified as one for the purposes of the law' # （法庭）當事人；⋯⋯方\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-missouri",
   "metadata": {
    "id": "premier-missouri"
   },
   "source": [
    "### 1. Load data\n",
    "\n",
    "The data is a set of sentences containing the word *party*, all extracted from wikipedia. The uniqueness of each sentence is guaranteed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-damages",
   "metadata": {
    "id": "polish-damages"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "available-skiing",
   "metadata": {
    "id": "available-skiing"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('.', 'party.train.txt'), 'r') as f:\n",
    "    data = f.read().strip().split('\\n')\n",
    "\n",
    "# this dict maps sentence_id to the sentence itself\n",
    "pure_data = { sent_id: text for sent_id, text in [line.split('\\t', 1) \n",
    "                                                 for line in data] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-stage",
   "metadata": {
    "id": "functional-stage"
   },
   "source": [
    "Let's see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "missing-replacement",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "missing-replacement",
    "outputId": "a8146199-6083-44e3-f7bc-aef4a49c30dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001: A naked party, also known as nude party, is a party where the participants are required to be nude.\n",
      "1002: The town center bears the hallmarks of a typical migration-accepting Turkish rural town, with traditional structures coexisting with a collection of concrete apartment blocks providing public housing, as well as amenities such as basic shopping and fast-food restaurants, and essential infrastructure but little in the way of culture except for cinemas and large rooms hired out for wedding parties.\n",
      "1003: Elections Alberta oversees the creation of political parties and riding associations, compiles election statistics on ridings, and collects financial statements from party candidates and riding associations.\n"
     ]
    }
   ],
   "source": [
    "for sent_id, sentence in pure_data.items():\n",
    "    if int(sent_id) > 1003: break\n",
    "        \n",
    "    print(f'{sent_id}: {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sufficient-atmosphere",
   "metadata": {
    "id": "sufficient-atmosphere"
   },
   "outputs": [],
   "source": [
    "# a look up table from sentence to id\n",
    "id_mapper = {v: k for k, v in pure_data.items()}\n",
    "# a table for id to embedding; we will deal with this later\n",
    "processed_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-homeless",
   "metadata": {
    "id": "respiratory-homeless"
   },
   "source": [
    "We define 2 samples here to validate the preprocess during our coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "portable-scenario",
   "metadata": {
    "id": "portable-scenario"
   },
   "outputs": [],
   "source": [
    "samples = [\n",
    "    'Adnan Al-Hakim (died May 26, 1990) was the leader of the Najjadeh Party, an Arab nationalist party in Lebanon, for more than 30 years.',\n",
    "    'A block party or street party is a party in which many members of a single community congregate, either to observe an event of some importance or simply for mutual enjoyment.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-haven",
   "metadata": {
    "id": "revolutionary-haven"
   },
   "source": [
    "### 2. Preprocess the sentences \n",
    "\n",
    "<font color=\"red\">[TODO]</font> Define your preprocessing function to transform a sentence into tokens here.  \n",
    "\n",
    "\\-\n",
    "\n",
    "<small>\n",
    "*hint: If you can't get a high accuracy in the final result, you may want to come back and modify your preprocessing here.<br/>\n",
    "*hint: Think about what words are useful and what are useless when distinguishing a sense.\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arranged-marijuana",
   "metadata": {
    "id": "arranged-marijuana"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "    text = re.findall(\"[\\w']+\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420522b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "420522b8",
    "outputId": "c1f20f16-132b-46f1-c6c6-ef55c0bc302b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adnan', 'Al', 'Hakim', 'died', 'May']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens = [preprocess(sent) for sent in samples]\n",
    "sent_tokens[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-panel",
   "metadata": {
    "id": "systematic-panel"
   },
   "source": [
    "### 3. Transform sentences into embeddings\n",
    "\n",
    "For the simplicity, we are still using word2vec here, so you can copy-paste your code from previous week.  \n",
    "This is not required; you don't have to use word2vec if you want to train a embedding model along with the classifier.  \n",
    "\n",
    "<small>\\*Download w2v: [Google Code Archive](https://code.google.com/archive/p/word2vec/#Pretrained-word-and-phrase-vectors)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-above",
   "metadata": {
    "id": "peripheral-above"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "united-desperate",
   "metadata": {
    "id": "united-desperate"
   },
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(\n",
    "        os.path.join('.', 'GoogleNews-vectors-negative300.bin'), \n",
    "        binary = True\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5719b5cf",
   "metadata": {
    "id": "5719b5cf"
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "415058bb",
   "metadata": {
    "id": "415058bb"
   },
   "outputs": [],
   "source": [
    "def to_embedding(tokens):\n",
    "    embedding_dim=300\n",
    "    num_tokens=[]\n",
    "    for word in tokens:\n",
    "        if word in w2v:\n",
    "            num_tokens.append(word)\n",
    "    embedding_matrix = numpy.zeros((len(num_tokens), embedding_dim))\n",
    "    for i in num_tokens:\n",
    "        embedding_matrix[num_tokens.index(i)] = w2v[i]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20998f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20998f5b",
    "outputId": "bda47797-b9a5-4551-b3ca-401b4f395f09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.140625  ,  0.20703125, -0.12988281, ...,  0.03076172,\n",
       "         0.07080078,  0.484375  ],\n",
       "       [-0.0390625 ,  0.24804688,  0.00540161, ...,  0.2265625 ,\n",
       "         0.02404785, -0.01477051],\n",
       "       [ 0.05541992,  0.31640625,  0.27929688, ..., -0.06689453,\n",
       "         0.34179688,  0.27929688],\n",
       "       ...,\n",
       "       [ 0.06396484, -0.25585938, -0.08447266, ...,  0.02746582,\n",
       "         0.06494141,  0.06201172],\n",
       "       [-0.07666016, -0.10400391, -0.00175476, ..., -0.01965332,\n",
       "        -0.03442383,  0.0007515 ],\n",
       "       [-0.12695312,  0.20898438, -0.10644531, ...,  0.13476562,\n",
       "         0.01879883, -0.1484375 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [to_embedding(tokens) for tokens in sent_tokens]\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-calibration",
   "metadata": {
    "id": "simplified-calibration"
   },
   "source": [
    "### 4. Pad the sentences to the same length\n",
    "\n",
    "The input size of model is fixed. However, the sentence lengths are various.  \n",
    "An intuitive solution is to stuff some dummy values into arrays util they share the same size, and this is called *padding*.  \n",
    "\n",
    "<small>*<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\">tf.keras.preprocessing.sequence.pad_sequences</a></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial-victoria",
   "metadata": {
    "id": "initial-victoria"
   },
   "outputs": [],
   "source": [
    "# if you prefer numpy\n",
    "#import numpy as np\n",
    "# or if you prefer tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "SrcMKGjLEK8i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrcMKGjLEK8i",
    "outputId": "03593200-549a-4d6d-92ea-019bfb0320b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.140625  ,  0.20703125, -0.12988281, ...,  0.03076172,\n",
       "          0.07080078,  0.484375  ],\n",
       "        [-0.0390625 ,  0.24804688,  0.00540161, ...,  0.2265625 ,\n",
       "          0.02404785, -0.01477051],\n",
       "        [ 0.05541992,  0.31640625,  0.27929688, ..., -0.06689453,\n",
       "          0.34179688,  0.27929688],\n",
       "        ...,\n",
       "        [ 0.06396484, -0.25585938, -0.08447266, ...,  0.02746582,\n",
       "          0.06494141,  0.06201172],\n",
       "        [-0.07666016, -0.10400391, -0.00175476, ..., -0.01965332,\n",
       "         -0.03442383,  0.0007515 ],\n",
       "        [-0.12695312,  0.20898438, -0.10644531, ...,  0.13476562,\n",
       "          0.01879883, -0.1484375 ]]),\n",
       " array([[-0.10595703,  0.21386719,  0.11865234, ...,  0.10693359,\n",
       "          0.02368164, -0.03540039],\n",
       "        [ 0.11328125,  0.06835938,  0.25      , ...,  0.03564453,\n",
       "          0.07226562,  0.01519775],\n",
       "        [-0.09130859, -0.08691406, -0.01208496, ...,  0.02832031,\n",
       "         -0.23242188,  0.11962891],\n",
       "        ...,\n",
       "        [-0.01177979, -0.04736328,  0.04467773, ...,  0.07128906,\n",
       "         -0.03491211,  0.02416992],\n",
       "        [-0.09521484,  0.19335938,  0.00172424, ..., -0.01611328,\n",
       "         -0.00836182, -0.12304688],\n",
       "        [ 0.27148438, -0.07958984, -0.05859375, ..., -0.25585938,\n",
       "          0.12402344, -0.17578125]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "inside-still",
   "metadata": {
    "id": "inside-still"
   },
   "outputs": [],
   "source": [
    "def add_padding(embeddings):\n",
    "    # [ TODO ]\n",
    "    # Pad all embeddings to padding_width, or detect it automatically when it's not given\n",
    "    # ps. tensorflow's `pad_sequences` can detect that for you\n",
    "    embeddings = [sent.tolist() for sent in embeddings]\n",
    "    embeddings = pad_sequences(embeddings, padding='pre', value=[0]*300, dtype='float32')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "_YNuTOrvDvN9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YNuTOrvDvN9",
    "outputId": "78fe8f3f-b657-41f6-f149-75a43dc1b33b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.06396484, -0.25585938, -0.08447266, ...,  0.02746582,\n",
       "         0.06494141,  0.06201172],\n",
       "       [-0.07666016, -0.10400391, -0.00175476, ..., -0.01965332,\n",
       "        -0.03442383,  0.0007515 ],\n",
       "       [-0.12695312,  0.20898438, -0.10644531, ...,  0.13476562,\n",
       "         0.01879883, -0.1484375 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_padded = add_padding(embeddings)\n",
    "emb_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wanted-brazilian",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wanted-brazilian",
    "outputId": "99618169-54ed-4d4f-9759-4fe552d1ebaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 26\n",
      "(26, 300) (26, 300)\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings[0]), len(embeddings[1]))\n",
    "print(emb_padded[0].shape, emb_padded[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-talent",
   "metadata": {
    "id": "brazilian-talent"
   },
   "source": [
    "You should see the embedding of shorter sentence is padded by empty arrays, and they are at the same length now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "boring-building",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boring-building",
    "outputId": "9426b1fb-7f4d-47ba-acc2-adf86983792b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# record the width for the future use.\n",
    "PADDING_WIDTH = emb_padded[0].shape[0]\n",
    "print(PADDING_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-postage",
   "metadata": {
    "id": "official-postage"
   },
   "source": [
    "### 5. all-in-one\n",
    "\n",
    "Define a function to setup the pipeline, and transform all sentences into embeddings!  \n",
    "\n",
    "<small>\\*Your embedding shape might not be the same with ours due to our different preprocessing procedure. </small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "greater-royalty",
   "metadata": {
    "id": "greater-royalty"
   },
   "outputs": [],
   "source": [
    "def process_text(sentences):\n",
    "    result = [ preprocess(sentence) for sentence in sentences ]\n",
    "    result = [ to_embedding(sentence) for sentence in result ]\n",
    "    result = add_padding(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ranking-motel",
   "metadata": {
    "id": "ranking-motel"
   },
   "outputs": [],
   "source": [
    "X = process_text(pure_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sUoB4HjUPklz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUoB4HjUPklz",
    "outputId": "d1625ad6-db99-4bd5-f932-e3115a339d84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.12890625, -0.18261719,  0.10351562, ..., -0.07714844,\n",
       "        -0.11572266, -0.02832031],\n",
       "       [-0.22851562, -0.08837891,  0.12792969, ..., -0.21289062,\n",
       "         0.18847656, -0.14550781],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "gross-kelly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gross-kelly",
    "outputId": "b60fde26-8d23-44f0-9b75-2207766feda4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 84, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # should be (637, *, 300), * depends on your preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-punishment",
   "metadata": {
    "id": "cheap-punishment"
   },
   "source": [
    "Let's use a dictionary to store all embeddings with their sentence_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "transparent-environment",
   "metadata": {
    "id": "transparent-environment"
   },
   "outputs": [],
   "source": [
    "processed_data = { \n",
    "    sent_id: embedding for sent_id, embedding in zip(pure_data, X) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "boxed-gossip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boxed-gossip",
    "outputId": "45d4c02e-782e-4b8a-dfe6-780b3b55f952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A naked party, also known as nude party, is a party where the participants are required to be nude.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.12890625, -0.18261719,  0.10351562, ..., -0.07714844,\n",
       "        -0.11572266, -0.02832031],\n",
       "       [-0.22851562, -0.08837891,  0.12792969, ..., -0.21289062,\n",
       "         0.18847656, -0.14550781],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pure_data['1001'])\n",
    "processed_data['1001']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-vinyl",
   "metadata": {
    "id": "directed-vinyl"
   },
   "source": [
    "## II. First stage\n",
    "\n",
    "After preprocessing the training data, now we are going to train our first-stage model!  \n",
    "\n",
    "According to the method described at the beginning, we can train a simple model on a smaller dataset, and this dataset can be generated by rule from seeds.  \n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Prepare the training data\n",
    "2. Encode labels\n",
    "3. Split training and testing dataset\n",
    "4. Build classifier\n",
    "5. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-consensus",
   "metadata": {
    "id": "solid-consensus"
   },
   "source": [
    "### 1. Prepare the training data\n",
    "\n",
    "Given the seed collocationss, you can add a sentence into the training data with label if that sentence contains that collocation.  \n",
    "For example, we can say <i>\"A party is a **social** gathering.\"</i> should be the first sense, because it contains the keyword *social*. Hence, your training data will have this sentence with its label `1`.  \n",
    "\n",
    "Don't worry about the false-positive cases for now.  \n",
    "If the seed is generally good enough, the model will learn to ignore those wrong data by itself. (though yeah, you can get better results if you deal with it beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "magnetic-humidity",
   "metadata": {
    "id": "magnetic-humidity"
   },
   "outputs": [],
   "source": [
    "SEEDS = {\n",
    "    1: ['social', 'events'],\n",
    "    2: ['system', 'coalition'],\n",
    "    3: ['court', 'law']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-pricing",
   "metadata": {
    "id": "sonic-pricing"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Get the initial training data from the given seeds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "hourly-power",
   "metadata": {
    "id": "hourly-power"
   },
   "outputs": [],
   "source": [
    "# [TODO]\n",
    "indice, first_X, first_Y = [], [], [] # sentence id of selected samples, selected sentences, detected labels\n",
    "for sent_id, sentence in pure_data.items():\n",
    "    for key, value in SEEDS.items():\n",
    "        if (value[0] in sentence) or (value[1] in sentence):\n",
    "            indice.append(sent_id)\n",
    "            first_X.append(sentence)\n",
    "            first_Y.append(key)\n",
    "first_X = process_text(first_X)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-matthew",
   "metadata": {
    "id": "universal-matthew"
   },
   "source": [
    "Examine training data.  \n",
    "The labels might not be 100% correct, but it should look reasonable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "yt-JWvmjVxnf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yt-JWvmjVxnf",
    "outputId": "5932609d-f3da-41d5-9168-04dbd205700c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From these social conventions derive in turn also the variants worn on related occasions of varying solemnity, such as formal political, diplomatic, and academic events, in addition to certain parties including award ceremonies, balls, fraternal orders, high school proms, etc.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "The Free-minded People's Party () or Radical People's Party was a social liberal party in the German Empire, founded as a result of the split of the German Free-minded Party in 1893.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "Typically, a party has the right to object in court to a line of questioning or at the introduction of a particular piece of evidence.\n",
      " -> 3: a single entity which can be identified as one for the purposes of the law\n",
      "\n",
      "Dizzy bat is commonly played at parties, colleges and universities, bars, and other drinking festivities such as a tailgate party at sporting events and concerts.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "Party of Peace and Unity (Партия Мира и Единства, \"Partiya Mira i Yedinstva\") was a socialist party in Russia.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(pure_data[indice[i]])\n",
    "    print(f' -> {first_Y[i]}: {SENSE[first_Y[i]]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-channel",
   "metadata": {
    "id": "fifteen-channel"
   },
   "source": [
    "Transform X and Y into numpy array for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "polar-halloween",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "polar-halloween",
    "outputId": "e7f2aa2c-3452-4341-a090-bc9f5db16272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 84, 300)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_X = np.array(first_X)\n",
    "first_Y = np.array(first_Y)\n",
    "first_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-modeling",
   "metadata": {
    "id": "original-modeling"
   },
   "source": [
    "### 2. Encode labels\n",
    "\n",
    "The labels now are all categorical, which are `1`, `2`, and `3` . However, it's hard to teach a machine this kind of answers.  \n",
    "Most of the time, machine learning generates a *numeric probability*, like `0.329`, rather than a categorical result.  \n",
    "That's why we want to encode the label into a floating point between 0 ~ 1, so that the machine can generate the probability of each answer.  \n",
    "\n",
    "Here we suggest you use the one-hot encoding, which is suitable for categorical classification.  \n",
    "So the label `2` will look like\n",
    "```\n",
    " Sense 1, Sense 2, Sense 3\n",
    "[      0,       1,       0]\n",
    "```\n",
    "\n",
    "*<small><a href=\"https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\">Why One-Hot Encode Data in Machine Learning?</a></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "turkish-noise",
   "metadata": {
    "id": "turkish-noise"
   },
   "outputs": [],
   "source": [
    "# if you prefer tensorflow\n",
    "from tensorflow import one_hot\n",
    "# or if you don't like tensorflow\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-ivory",
   "metadata": {
    "id": "universal-ivory"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> one-hot encode `first_Y`\n",
    "\n",
    "<small>\n",
    "*<a href=\"https://www.tensorflow.org/api_docs/python/tf/one_hot\">tf.one_hot</a><br/>\n",
    "*<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">sklearn.preprocessing.OneHotEncoder</a>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "MFvHeR1fohCQ",
   "metadata": {
    "id": "MFvHeR1fohCQ"
   },
   "outputs": [],
   "source": [
    "a = first_Y.tolist()\n",
    "a = [(i-1) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "r_AnYHNRn2Ex",
   "metadata": {
    "id": "r_AnYHNRn2Ex"
   },
   "outputs": [],
   "source": [
    "depth = 3\n",
    "first_Y = one_hot(a, depth, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "executed-alabama",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "executed-alabama",
    "outputId": "de3c0b63-1033-436b-8bc5-6eaac943d7b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(201, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-regulation",
   "metadata": {
    "id": "painted-regulation"
   },
   "source": [
    "### 3. Prepare training and validation set\n",
    "\n",
    "Split the dataset into training set and validation set.  \n",
    "The reason for splitting is because, you may not want the model to see what you'll use to test it when it is still learning.\n",
    "\n",
    "Machine is very smart; sometimes it just *memorizes* the answers, rather than *learns* them. Even that the model has yielded a perfect accuracy in the test, it still might fail miserably when facing the cruel, real world. *(heh)*  \n",
    "That's why we need a validation set. We reserve a partition of data that will never be learnt by the model, and use it to validate whether the model really learns someting.\n",
    "\n",
    "<small>*<a href=\"https://tarangshah.com/blog/2017-12-03/train-validation-and-test-sets/\">Train, Validation and Test Sets</a></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "buried-protection",
   "metadata": {
    "id": "buried-protection"
   },
   "outputs": [],
   "source": [
    "# if you prefer sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# or if you don't like sklearn. **Remember to shuffle your data before splitting.**\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fl5pBC8vwR7h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fl5pBC8vwR7h",
    "outputId": "e3ced3a4-9e4c-40d3-91e9-ebf160c82fec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(first_Y))\n",
    "first_Y=first_Y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bridal-banks",
   "metadata": {
    "id": "bridal-banks"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    first_X, first_Y,\n",
    "    test_size = 0.2,   # [TODO] How much data you want to used as validation set\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "confidential-merchandise",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "confidential-merchandise",
    "outputId": "54ec3b61-0fb5-4384-e3e7-4a73b4fefbbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 84, 300) (41, 84, 300) (160, 3) (41, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-qualification",
   "metadata": {
    "id": "bronze-qualification"
   },
   "source": [
    "### 4. Build your multi-labeling classifier \n",
    "\n",
    "Now the data is all prepared.  \n",
    "Let's build a model to learn from it!  \n",
    "\n",
    "Note that, different from last week, your output dimension should be the size of all categories, rather than `2` .  \n",
    "\n",
    "\\-\n",
    "\n",
    "<small>\n",
    "*Although tensorflow is used below, you can always change it to any other framework you are familiar with. <br/>\n",
    "*<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers\">tf.keras.layers</a>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "healthy-strength",
   "metadata": {
    "id": "healthy-strength"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense#, and all the other layers you may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "alternative-pasta",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alternative-pasta",
    "outputId": "508793d2-1504-4604-c547-e1255404021b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 300 3\n"
     ]
    }
   ],
   "source": [
    "_, PADDING_WIDTH, EMBEDDING_DIM = X_train.shape\n",
    "OUTPUT_CATEGORY = len(SENSE)\n",
    "\n",
    "print(PADDING_WIDTH, EMBEDDING_DIM, OUTPUT_CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-captain",
   "metadata": {
    "id": "universal-captain"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "alike-context",
   "metadata": {
    "id": "alike-context"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "input_shape = (None, X_train.shape[1], X_train.shape[2])\n",
    "model.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "esGu31bayUmq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esGu31bayUmq",
    "outputId": "54aae3af-5386-4715-e661-d5677d476c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,723\n",
      "Trainable params: 42,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-dressing",
   "metadata": {
    "id": "severe-dressing"
   },
   "source": [
    "Time to choose the optimizer and loss function.  \n",
    "\n",
    "Loss function is an equation evaluating how wrong your model has answered (the lower the better), while optimizer tells the model how to improve itself.  \n",
    "But seriously, we are not asking you to fine-tune these parameters. That is for Machine Learning class, not for NLP class, so if you are not able to pass the baseline, go check your processing procedure first. Something might go wrong there.  \n",
    "\n",
    "\\-\n",
    "\n",
    "<small>\n",
    "*<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\">tf.keras.model#compile</a> <br/>\n",
    "*<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\">tf.keras.optimizers</a> <br/>\n",
    "*<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/losses\">tf.keras.losses</a>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-palace",
   "metadata": {
    "id": "affected-palace"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "medium-indie",
   "metadata": {
    "id": "medium-indie"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-needle",
   "metadata": {
    "id": "overhead-needle"
   },
   "source": [
    "### 5. Train \n",
    "\n",
    "Time to train your model!  \n",
    "\n",
    "You should always prevent the model from overfitting, so take validation accuracy into consideration and choose your epoch number wisely.  \n",
    "\n",
    "<small>*<a href=\"https://www.ibm.com/cloud/learn/overfitting\">What is Overfitting?</a></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-wisdom",
   "metadata": {
    "id": "collaborative-wisdom"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Train and tune your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "expensive-anthropology",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "expensive-anthropology",
    "outputId": "ca46bf20-0ef5-4517-8b37-6a3e82383b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 2s 137ms/step - loss: 1.0322 - accuracy: 0.4812 - val_loss: 0.9882 - val_accuracy: 0.5122\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.9313 - accuracy: 0.5125 - val_loss: 0.9392 - val_accuracy: 0.4878\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.8446 - accuracy: 0.5250 - val_loss: 0.9024 - val_accuracy: 0.4878\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.7762 - accuracy: 0.6125 - val_loss: 0.8534 - val_accuracy: 0.5854\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.6890 - accuracy: 0.7312 - val_loss: 0.7896 - val_accuracy: 0.6585\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5988 - accuracy: 0.7688 - val_loss: 0.7118 - val_accuracy: 0.6585\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5006 - accuracy: 0.7812 - val_loss: 0.6047 - val_accuracy: 0.6829\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4211 - accuracy: 0.8250 - val_loss: 0.5384 - val_accuracy: 0.6585\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3692 - accuracy: 0.8375 - val_loss: 0.4229 - val_accuracy: 0.8049\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3226 - accuracy: 0.9250 - val_loss: 0.3439 - val_accuracy: 0.9024\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2761 - accuracy: 0.9375 - val_loss: 0.3412 - val_accuracy: 0.9268\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2414 - accuracy: 0.9375 - val_loss: 0.2808 - val_accuracy: 0.9268\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.2076 - accuracy: 0.9500 - val_loss: 0.2749 - val_accuracy: 0.9268\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1908 - accuracy: 0.9438 - val_loss: 0.2472 - val_accuracy: 0.9268\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1875 - accuracy: 0.9563 - val_loss: 0.2164 - val_accuracy: 0.9268\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train, \n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs = 15          # [TODO] how many iterations you want to run\n",
    "    #initial_epoch = 3    # set this if you're continuing previous training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-economics",
   "metadata": {
    "id": "raised-economics"
   },
   "source": [
    "### 6. Examine your model\n",
    "\n",
    "Let's see how good your model does.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "beginning-range",
   "metadata": {
    "id": "beginning-range"
   },
   "outputs": [],
   "source": [
    "testcases = [\n",
    "    # 1\n",
    "    'A block party or street party is a party in which many members of a single community congregate, either to observe an event of some importance or simply for mutual enjoyment.',\n",
    "    'A party is a social gathering.',\n",
    "    # 2\n",
    "    'Ukraine has a multi-party system, with numerous parties in which often not a single party has a chance of gaining power alone, and parties must work with each other to form coalition governments.',\n",
    "    'Serbia has a multi-party system, with numerous parties in which no one party often has a chance of gaining power alone, and parties must work with each other to form coalition governments.',\n",
    "    # 3\n",
    "    'In a civil lawsuit, a nominal party is one named as a party on the record of an action, but having no interest in the action.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "alone-strengthening",
   "metadata": {
    "id": "alone-strengthening"
   },
   "outputs": [],
   "source": [
    "# you must specify the padding width here, since the input size of model should always be the same\n",
    "test_X = process_text(testcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "relative-month",
   "metadata": {
    "id": "relative-month"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "packed-ocean",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "packed-ocean",
    "outputId": "1be0116f-dc23-418e-cdb1-684a49ed7218"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5890655 , 0.10217339, 0.30876106], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-bracelet",
   "metadata": {
    "id": "silent-bracelet"
   },
   "source": [
    "#### What does the result mean?\n",
    "\n",
    "As you can see, a list of floats are generated, and since we used one-hot encoding when preparing the training data, each number presents the result of corresponding categories.  \n",
    "```\n",
    " Sense 1, Sense 2, Sense 3\n",
    "[   0.89,    0.12,    0.21]\n",
    "```\n",
    "You can consider these values as the probability of each column, or said category. Hence, the true predicted label should be the one with the highest probability, which is Sense 1 for this sample.  \n",
    "\n",
    "Now let's get all the predicted labels from these probabilities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "suspended-sending",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suspended-sending",
    "outputId": "086c33b6-1307-4a9d-fb7e-4cc3ce0df18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A block party or street party is a party in which many members of a single community congregate, either to observe an event of some importance or simply for mutual enjoyment.\n",
      "-> Sense 1 (prob=0.59): a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "A party is a social gathering.\n",
      "-> Sense 1 (prob=0.52): a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "Ukraine has a multi-party system, with numerous parties in which often not a single party has a chance of gaining power alone, and parties must work with each other to form coalition governments.\n",
      "-> Sense 2 (prob=1.00): an organization of people with particular political beliefs\n",
      "\n",
      "Serbia has a multi-party system, with numerous parties in which no one party often has a chance of gaining power alone, and parties must work with each other to form coalition governments.\n",
      "-> Sense 2 (prob=1.00): an organization of people with particular political beliefs\n",
      "\n",
      "In a civil lawsuit, a nominal party is one named as a party on the record of an action, but having no interest in the action.\n",
      "-> Sense 3 (prob=0.93): a single entity which can be identified as one for the purposes of the law\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(predictions):\n",
    "    predict_id = result.argmax() # select the index of the maximum value\n",
    "    sense_id = predict_id + 1    # sense_id starts from 1\n",
    "    print(testcases[idx])\n",
    "    print(f'-> Sense {sense_id} (prob={result[predict_id]:.2f}): {SENSE[sense_id]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-maldives",
   "metadata": {
    "id": "brave-maldives"
   },
   "source": [
    "Again, the label might not be 100% correct, but it should look reasonable somehow.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-license",
   "metadata": {
    "id": "residential-license"
   },
   "source": [
    "## III. Second stage\n",
    "\n",
    "The previous model might not be enough for real-world use; another model with better ability is needed.  \n",
    "\n",
    "<small>*Most contents of this section are the same as previous one, so you can make use of your code above.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-success",
   "metadata": {
    "id": "vocal-success"
   },
   "source": [
    "### 1. Prepare the training data \n",
    "\n",
    "The model from the previous section is weak, yet it still has learned some valuable knowledge.  \n",
    "Let's ask that model to label more training data for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "blank-child",
   "metadata": {
    "id": "blank-child"
   },
   "outputs": [],
   "source": [
    "# Get the probability on the whold dataset\n",
    "predictions = model.predict(np.array(list(processed_data.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-committee",
   "metadata": {
    "id": "acoustic-committee"
   },
   "source": [
    "\n",
    "<font color=\"red\">[TODO]</font> Get the labels of all data, and reserve only those labels with high probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "powerful-debut",
   "metadata": {
    "id": "powerful-debut"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5  # you may want to change this :)\n",
    "indice, second_X, second_Y = [], [], [] # sentence id of selected samples, selected sentences, detected labels\n",
    "\n",
    "for sent_id, result in zip(processed_data, predictions):\n",
    "    if result[0] >= THRESHOLD :\n",
    "        indice.append(sent_id)\n",
    "        second_X.append(processed_data[sent_id])\n",
    "        second_Y.append(1)\n",
    "    elif result[1] >= THRESHOLD :\n",
    "        indice.append(sent_id)\n",
    "        second_X.append(processed_data[sent_id])\n",
    "        second_Y.append(2)\n",
    "    elif result[2] >= THRESHOLD :\n",
    "        indice.append(sent_id)\n",
    "        second_X.append(processed_data[sent_id])\n",
    "        second_Y.append(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-python",
   "metadata": {
    "id": "artificial-python"
   },
   "source": [
    "Observe the selected data size and the quality of labels.  \n",
    "You might want to go back and modify your preprocessing, first model, or the threshold until you get a better training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "02bb78d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02bb78d4",
    "outputId": "9a484052-9109-42f0-9c3a-fe5e3f624a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The town center bears the hallmarks of a typical migration-accepting Turkish rural town, with traditional structures coexisting with a collection of concrete apartment blocks providing public housing, as well as amenities such as basic shopping and fast-food restaurants, and essential infrastructure but little in the way of culture except for cinemas and large rooms hired out for wedding parties.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "Elections Alberta oversees the creation of political parties and riding associations, compiles election statistics on ridings, and collects financial statements from party candidates and riding associations.\n",
      " -> 2: an organization of people with particular political beliefs\n",
      "\n",
      "From these social conventions derive in turn also the variants worn on related occasions of varying solemnity, such as formal political, diplomatic, and academic events, in addition to certain parties including award ceremonies, balls, fraternal orders, high school proms, etc.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "(, \"Al-Harakat al-Wataniyya al-Lubnaniyya\") or Mouvement National Libanais (MNL) in French, was a front of leftist, pan-Arabist and Syrian nationalist parties and organizations active during the early years of the Lebanese Civil War, which supported the Palestine Liberation Organization (PLO).\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "The Free-minded People's Party () or Radical People's Party was a social liberal party in the German Empire, founded as a result of the split of the German Free-minded Party in 1893.\n",
      " -> 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(pure_data[indice[i]])\n",
    "    print(f' -> {second_Y[i]}: {SENSE[second_Y[i]]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "thirty-narrative",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thirty-narrative",
    "outputId": "06dcdbd4-1211-437b-ad61-8e68872b847c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 84, 300)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_X = np.array(second_X)\n",
    "second_Y = np.array(second_Y)\n",
    "second_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-california",
   "metadata": {
    "id": "elect-california"
   },
   "source": [
    "### 2. Encode labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-constant",
   "metadata": {
    "id": "bright-constant"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> one-hot encode secone_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "transparent-fraction",
   "metadata": {
    "id": "transparent-fraction"
   },
   "outputs": [],
   "source": [
    "second_Y_list = second_Y.tolist()\n",
    "second_Y_list = [(i-1) for i in second_Y_list]\n",
    "second_Y = one_hot(second_Y_list, depth, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "champion-calculation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "champion-calculation",
    "outputId": "c09301fd-d39e-4a7e-9069-66784406041f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_Y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-visiting",
   "metadata": {
    "id": "loose-visiting"
   },
   "source": [
    "### 3. Prepare training and validating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "rocky-friendly",
   "metadata": {
    "id": "rocky-friendly"
   },
   "outputs": [],
   "source": [
    "second_Y=second_Y.numpy()\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    second_X, second_Y,\n",
    "    test_size = 0.2,    # [TODO] How much data you want to used as validation set\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "collectible-threat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "collectible-threat",
    "outputId": "0a4057bc-0f04-46ea-c854-d5dc38d4467e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456, 84, 300)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-enclosure",
   "metadata": {
    "id": "annual-enclosure"
   },
   "source": [
    "### 4. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "synthetic-wagon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "synthetic-wagon",
    "outputId": "614939f7-51ac-418d-80c6-722520afe348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 300 3\n"
     ]
    }
   ],
   "source": [
    "# the number comes from previous setting\n",
    "print(PADDING_WIDTH, EMBEDDING_DIM, OUTPUT_CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-canadian",
   "metadata": {
    "id": "alone-canadian"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Build your second model\n",
    "\n",
    "<small>*This model can be different from the previous one.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "qev9UwP1b1Es",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qev9UwP1b1Es",
    "outputId": "d2c5610e-7a6d-478e-f434-df5a454b110c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 32)                42624     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,723\n",
      "Trainable params: 42,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(LSTM(32))\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "input_shape = (None, X_train.shape[1], X_train.shape[2])\n",
    "model_2.build(input_shape)\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-western",
   "metadata": {
    "id": "beneficial-western"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "found-intent",
   "metadata": {
    "id": "found-intent"
   },
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-birth",
   "metadata": {
    "id": "previous-birth"
   },
   "source": [
    "### 5. Train model\n",
    "\n",
    "<font color=\"red\">[TODO]</font> Train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "noticed-import",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noticed-import",
    "outputId": "195b7a40-bb54-4510-be6c-2c26751f6912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 3s 66ms/step - loss: 1.0695 - accuracy: 0.4364 - val_loss: 0.9791 - val_accuracy: 0.6579\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.9233 - accuracy: 0.6732 - val_loss: 0.7929 - val_accuracy: 0.7719\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.6401 - accuracy: 0.8399 - val_loss: 0.4847 - val_accuracy: 0.8772\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4052 - accuracy: 0.8684 - val_loss: 0.4960 - val_accuracy: 0.8421\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3291 - accuracy: 0.8794 - val_loss: 0.3285 - val_accuracy: 0.8947\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.2641 - accuracy: 0.9232 - val_loss: 0.3586 - val_accuracy: 0.8772\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2127 - accuracy: 0.9474 - val_loss: 0.3431 - val_accuracy: 0.9035\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.1614 - accuracy: 0.9627 - val_loss: 0.2914 - val_accuracy: 0.9123\n",
      "Epoch 9/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1292 - accuracy: 0.9715 - val_loss: 0.2980 - val_accuracy: 0.9298\n",
      "Epoch 10/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.1116 - accuracy: 0.9737 - val_loss: 0.2222 - val_accuracy: 0.9298\n",
      "Epoch 11/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1080 - accuracy: 0.9715 - val_loss: 0.2005 - val_accuracy: 0.9386\n",
      "Epoch 12/15\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0946 - accuracy: 0.9715 - val_loss: 0.2218 - val_accuracy: 0.9386\n",
      "Epoch 13/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0646 - accuracy: 0.9868 - val_loss: 0.2034 - val_accuracy: 0.9474\n",
      "Epoch 14/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0611 - accuracy: 0.9846 - val_loss: 0.3361 - val_accuracy: 0.8947\n",
      "Epoch 15/15\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0530 - accuracy: 0.9890 - val_loss: 0.2110 - val_accuracy: 0.9386\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(\n",
    "    X_train, Y_train, \n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs = 15,        # [TODO] how many iterations you want to run\n",
    "    # initial_epoch = ?  # set this if you're continuing previous training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-bailey",
   "metadata": {
    "id": "southeast-bailey"
   },
   "source": [
    "### 6. Examine the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "atlantic-spine",
   "metadata": {
    "id": "atlantic-spine"
   },
   "outputs": [],
   "source": [
    "testcases = [\n",
    "    # 1\n",
    "    'Green Beer Day (GBD) is a day-long party, where celebrants drink beer dyed green with artificial coloring or natural processes.',\n",
    "    'When the siblings grew up, they held parties and introduced the tradition to friends while in college, and the tradition began to spread.',\n",
    "    # 2\n",
    "    'Politicians from the two main parties tend to win elections when not confronted by strong challengers from their own party (in which cases their traditional opponents tend to win).',\n",
    "    'After the general election on 22 March 1992, five parties (Rassadorn, Justice Unity, Social Action, Thai Citizen, Chart Thai) designated Suchinda as the prime minister.',\n",
    "    # 3\n",
    "    'Typically, a party has the right to object in court to a line of questioning or at the introduction of a particular piece of evidence.',\n",
    "    'In the practice of law, judicial estoppel (also known as estoppel by inconsistent positions) is an estoppel that precludes a party from taking a position in a case that is contrary to a position it has taken in earlier legal proceedings.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "taken-printer",
   "metadata": {
    "id": "taken-printer"
   },
   "outputs": [],
   "source": [
    "# you must specify the padding width! \n",
    "test_X = process_text(testcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "entitled-brief",
   "metadata": {
    "id": "entitled-brief"
   },
   "outputs": [],
   "source": [
    "predictions = model_2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "reserved-small",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "reserved-small",
    "outputId": "59fd3fec-d3aa-4347-891d-18e1b0e0738f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Beer Day (GBD) is a day-long party, where celebrants drink beer dyed green with artificial coloring or natural processes.\n",
      "-> Sense 1 (prob=0.99): a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "When the siblings grew up, they held parties and introduced the tradition to friends while in college, and the tradition began to spread.\n",
      "-> Sense 1 (prob=0.96): a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "Politicians from the two main parties tend to win elections when not confronted by strong challengers from their own party (in which cases their traditional opponents tend to win).\n",
      "-> Sense 2 (prob=0.99): an organization of people with particular political beliefs\n",
      "\n",
      "After the general election on 22 March 1992, five parties (Rassadorn, Justice Unity, Social Action, Thai Citizen, Chart Thai) designated Suchinda as the prime minister.\n",
      "-> Sense 2 (prob=0.99): an organization of people with particular political beliefs\n",
      "\n",
      "Typically, a party has the right to object in court to a line of questioning or at the introduction of a particular piece of evidence.\n",
      "-> Sense 3 (prob=0.98): a single entity which can be identified as one for the purposes of the law\n",
      "\n",
      "In the practice of law, judicial estoppel (also known as estoppel by inconsistent positions) is an estoppel that precludes a party from taking a position in a case that is contrary to a position it has taken in earlier legal proceedings.\n",
      "-> Sense 3 (prob=0.99): a single entity which can be identified as one for the purposes of the law\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(predictions):\n",
    "    predict_id = result.argmax()\n",
    "    sense_id = predict_id + 1    # sense_id starts from 1\n",
    "    print(testcases[idx])\n",
    "    print(f'-> Sense {sense_id} (prob={result[predict_id]:.2f}): {SENSE[sense_id]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-march",
   "metadata": {
    "id": "gothic-march"
   },
   "source": [
    "Yet again, the label might not be 100% correct, but it still should look reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-ottawa",
   "metadata": {
    "id": "armed-ottawa"
   },
   "source": [
    "## IV. Evaluation\n",
    "\n",
    "We have our model built! It's time to see how good it is on the testing dataset.  \n",
    "Get the predictions from the final model and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "exact-anthony",
   "metadata": {
    "id": "exact-anthony"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('.', 'party.test.txt'), 'r') as f:\n",
    "    data = f.read().strip().split('\\n')\n",
    "\n",
    "# this dict maps sentence_id to the sentence itself\n",
    "test_data = { sent_id: text for sent_id, text in [line.split('\\t', 1) \n",
    "                                                 for line in data] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "QT9jc2XxnB3G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QT9jc2XxnB3G",
    "outputId": "4f37082a-671d-48af-d1b0-87e1fd11536c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "brief-credits",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brief-credits",
    "outputId": "1756c8e3-5660-4e0e-90a1-ebf5eecaad9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638: Patent ambiguity is that ambiguity which is apparent on the face of an instrument to any one perusing it, even if unacquainted with the circumstances of the parties.\n",
      "1639: Smith played at parties, juke joints, and fish fries.\n",
      "1640: Turkey has a multi-party system, with two or three strong parties and often a fourth party that is electorally successful.\n",
      "1641: The Christian Liberation Movement ( or simply MCL) is a Cuban dissident party advocating political change in Cuba.\n"
     ]
    }
   ],
   "source": [
    "for idx, (sent_id, sentence) in enumerate(test_data.items()):\n",
    "    if idx > 3: break\n",
    "        \n",
    "    print(f'{sent_id}: {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-gambling",
   "metadata": {
    "id": "associate-gambling"
   },
   "source": [
    "<font color=\"red\">[TODO]</font> Get the labels of testing data.  \n",
    "\n",
    "Try to reserve the sentence id, because you will need it while requesting your accuracy.  \n",
    "Recommended format of `final_predictions` : \n",
    "```\n",
    "{ sent_id: sense_id }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "g93pHJDppZiR",
   "metadata": {
    "id": "g93pHJDppZiR"
   },
   "outputs": [],
   "source": [
    "test=[]\n",
    "for key,sentence in test_data.items():\n",
    "    test.append(sentence)\n",
    "test = process_text(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "lh41OcMtpTDM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lh41OcMtpTDM",
    "outputId": "ed5cf5f9-5f88-45e7-8388-c6e3a782ab62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 30 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eff908835f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "predictions = model_2.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "BjHWcDh1qNYK",
   "metadata": {
    "id": "BjHWcDh1qNYK"
   },
   "outputs": [],
   "source": [
    "sense_id=[]\n",
    "for idx, result in enumerate(predictions):\n",
    "    predict_id = result.argmax() # select the index of the maximum value\n",
    "    sense_id.append(predict_id + 1)    # sense_id starts from 1\n",
    "    #print(testcases[idx])\n",
    "    #print(f'-> Sense {sense_id} (prob={result[predict_id]:.2f}): {SENSE[sense_id]}')\n",
    "    #print(sense_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "lA8MsU-teX6W",
   "metadata": {
    "id": "lA8MsU-teX6W"
   },
   "outputs": [],
   "source": [
    "final_predictions = {}\n",
    "for idx, (sent_id, sentence) in enumerate(test_data.items()):\n",
    "    final_predictions[sent_id]=int(sense_id[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "EhG8oOzXnMXg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhG8oOzXnMXg",
    "outputId": "f5676919-5745-4c6d-ef6b-734cc232f643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "painful-creation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "painful-creation",
    "outputId": "89d6ab99-6cd3-485c-9860-433df549c14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638 Patent ambiguity is that ambiguity which is apparent on the face of an instrument to any one perusing it, even if unacquainted with the circumstances of the parties.\n",
      "-> Sense 3: a single entity which can be identified as one for the purposes of the law\n",
      "\n",
      "1639 Smith played at parties, juke joints, and fish fries.\n",
      "-> Sense 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "1640 Turkey has a multi-party system, with two or three strong parties and often a fourth party that is electorally successful.\n",
      "-> Sense 2: an organization of people with particular political beliefs\n",
      "\n",
      "1641 The Christian Liberation Movement ( or simply MCL) is a Cuban dissident party advocating political change in Cuba.\n",
      "-> Sense 1: a social event at which a group of people meet to talk, eat, drink, dance, etc.\n",
      "\n",
      "1642 Greens Party () was a green liberal party in Turkey.\n",
      "-> Sense 2: an organization of people with particular political beliefs\n",
      "\n",
      "1643 Under the Constitution of North Korea, all citizens 17 and older, regardless of party affiliation, political views, or religion, are eligible to be elected to the legislature and vote in elections.\n",
      "-> Sense 2: an organization of people with particular political beliefs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (sent_id, pred) in enumerate(final_predictions.items()):\n",
    "    if idx > 5: break\n",
    "        \n",
    "    print(sent_id, test_data[sent_id])\n",
    "    print(f'-> Sense {pred}: {SENSE[pred]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "rLzzvwVlroxE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLzzvwVlroxE",
    "outputId": "08bdc4b9-b165-404f-c64d-557a1287cdf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1638': 3,\n",
       " '1639': 1,\n",
       " '1640': 2,\n",
       " '1641': 1,\n",
       " '1642': 2,\n",
       " '1643': 2,\n",
       " '1644': 1,\n",
       " '1645': 1,\n",
       " '1646': 1,\n",
       " '1647': 2,\n",
       " '1648': 2,\n",
       " '1649': 3,\n",
       " '1650': 1,\n",
       " '1651': 1,\n",
       " '1652': 1,\n",
       " '1653': 3,\n",
       " '1654': 2,\n",
       " '1655': 2,\n",
       " '1656': 3,\n",
       " '1657': 2,\n",
       " '1658': 2,\n",
       " '1659': 3,\n",
       " '1660': 2,\n",
       " '1661': 1,\n",
       " '1662': 2,\n",
       " '1663': 2,\n",
       " '1664': 3,\n",
       " '1665': 2,\n",
       " '1666': 2,\n",
       " '1667': 2,\n",
       " '1668': 3,\n",
       " '1669': 2,\n",
       " '1670': 1,\n",
       " '1671': 2,\n",
       " '1672': 2,\n",
       " '1673': 3,\n",
       " '1674': 3,\n",
       " '1675': 3,\n",
       " '1676': 3,\n",
       " '1677': 2,\n",
       " '1678': 3,\n",
       " '1679': 1,\n",
       " '1680': 1,\n",
       " '1681': 1,\n",
       " '1682': 3,\n",
       " '1683': 3,\n",
       " '1684': 3,\n",
       " '1685': 2,\n",
       " '1686': 1,\n",
       " '1687': 1,\n",
       " '1688': 1,\n",
       " '1689': 3,\n",
       " '1690': 2,\n",
       " '1691': 2,\n",
       " '1692': 1,\n",
       " '1693': 2,\n",
       " '1694': 2,\n",
       " '1695': 3,\n",
       " '1696': 3,\n",
       " '1697': 1,\n",
       " '1698': 2,\n",
       " '1699': 3,\n",
       " '1700': 2,\n",
       " '1701': 1,\n",
       " '1702': 1,\n",
       " '1703': 1,\n",
       " '1704': 3,\n",
       " '1705': 2,\n",
       " '1706': 3,\n",
       " '1707': 2}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-physics",
   "metadata": {
    "id": "complicated-physics"
   },
   "source": [
    "### Get your accuracy\n",
    "\n",
    "Send your predictions in json format to our server, and we will calculate the accuracy for you.  \n",
    "The format should be \n",
    "```\n",
    "{ sentence_id: sense_id }\n",
    "```\n",
    "Example,\n",
    "```\n",
    "{\n",
    "    1001: 1,\n",
    "    1002: 1,\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "sustainable-medicaid",
   "metadata": {
    "id": "sustainable-medicaid"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "shaped-battery",
   "metadata": {
    "id": "shaped-battery"
   },
   "outputs": [],
   "source": [
    "data = json.dumps(final_predictions)\n",
    "ret = requests.post('http://jedi.nlplab.cc:4500/check', \n",
    "                    json = { 'data': data }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "impossible-viking",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "impossible-viking",
    "outputId": "1c01c07d-8c78-43cb-9b6f-4d1fadd813c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7142857142857143, 'comment': ['Well done!']}\n"
     ]
    }
   ],
   "source": [
    "if not ret.ok:\n",
    "    print('Something wrong :o')\n",
    "print(ret.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-acrobat",
   "metadata": {
    "id": "narrative-acrobat"
   },
   "source": [
    "**REQUIREMENT**  \n",
    "**Your accuracy should be <u>higher than 0.70</u> to get the full points.**\n",
    "\n",
    "But do note that your assignment is mostly scored on your implementation, not just on the accuracy.  \n",
    "So even if you brute-forcely attack our server and get 100% accuracy, you still can't get your points if your code doesn't make sense to TA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-thread",
   "metadata": {
    "id": "vocational-thread"
   },
   "source": [
    "## TA's note\n",
    "\n",
    "Congratuation! You've finished the assignment this week.  \n",
    "Don't forget to <b>[make an appoiment with TA](https://docs.google.com/spreadsheets/d/1QGeYl5dsD9sFO9SYg4DIKk-xr-yGjRDOOLKZqCLDv2E/edit#gid=1902646609) to demo/explain your implementation <u>before <font color=\"red\">11/18 15:30</font></u></b> .  \n",
    "Also make sure you submit your {student_id}.ipynb to [eeclass](https://eeclass.nthu.edu.tw/course/homework/4615).\n",
    "\n",
    "Please note that <font color=\"red\">we will announce our final project on 11/18</font>. Again, **we strongly suggest you join and listen** .  \n",
    "We will have 2 Ph.D. students introduce the selected topics in class and give you some guidelines about how to approach your project.  \n",
    "Also, we will have a team-matching session at the end of the class, in which you may want to participate to find teammates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-fleece",
   "metadata": {
    "id": "polar-fleece"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "revolutionary-haven",
    "systematic-panel",
    "simplified-calibration",
    "official-postage",
    "original-modeling",
    "painted-regulation",
    "bronze-qualification",
    "overhead-needle",
    "raised-economics",
    "silent-bracelet",
    "vocal-success",
    "elect-california",
    "loose-visiting",
    "annual-enclosure",
    "previous-birth",
    "southeast-bailey",
    "complicated-physics"
   ],
   "name": "Week09_word_sense_disambiguation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "90bd059e05f79fb9b7cf5d2b1dae6ea26ca779772e058f49dd8fbe1978749df0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
