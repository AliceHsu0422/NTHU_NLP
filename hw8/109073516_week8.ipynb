{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCvQruwXhOsD"
   },
   "source": [
    "# Week 08: Phrase Classification\n",
    "The assignment this week needs you to distinguish between good and bad phrases of the word \"**earn**\" (e.g., earn money). The method, word2vector, learned today will be used in the process. \n",
    "\n",
    "There're some data for this assignment: \n",
    "* train.tsv: Some phrases with labels to train and validate the classification model. There are only two types of label: 1 means *good*; 0 means *bad*.\n",
    "* test.tsv: Same format as train.tsv. It's used to test your model.\n",
    "* GoogleNews-vectors-negative300.bin.gz: a pre-trained word2vector model trained by Google ([source](https://code.google.com/archive/p/word2vec/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex3jWYYlhOsH"
   },
   "source": [
    "## Requirement\n",
    "* pandas\n",
    "* tensorflow\n",
    "* sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX3iQlm-jKgv"
   },
   "source": [
    "# Download word2vec data and training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcHK_m5nsGAh",
    "outputId": "52cb8821-6c12-4ccb-8ab5-80877e59229d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install googledrivedownloader\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1ekUZ1zGSs6UjM_jfmAOuzNCgcOyWdsyR',\n",
    "                                    dest_path='./GoogleNews-vectors-negative300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rMEye7OriZJg"
   },
   "outputs": [],
   "source": [
    "gdd.download_file_from_google_drive(file_id='1VAxq0DOAekM9DFVIvcig9bdwl4GEA6KD',\n",
    "                                    dest_path='./test.tsv')\n",
    "gdd.download_file_from_google_drive(file_id='1f6b8hmcfUFztzOhdKgnoCDpPewio1odl',\n",
    "                                    dest_path='./train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "W-bDBKKut9CN"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('GoogleNews-vectors-negative300.bin.gz', 'rb') as f_in:\n",
    "    with open('GoogleNews-vectors-negative300.bin', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVo8YeNBhOsH"
   },
   "source": [
    "## Read Data\n",
    "We use dataframe to store data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDE-jzD0hOsI",
    "outputId": "5b2bcb4f-6c6c-401f-9fc2-3b4dee9ec26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         phrase  class\n",
      "0      earn a strong reputation      1\n",
      "1  Marty will surely earn every      0\n",
      "2             to earn between $      0\n",
      "3          to earn some college      0\n",
      "4        that earn rave reviews      0\n",
      "                   phrase  class\n",
      "0  degree earn 62 percent      0\n",
      "1     earn maybe 30 or 50      0\n",
      "2  earn the kind of money      1\n",
      "3      earn his 14th save      1\n",
      "4   earn a smaller amount      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadData(path):\n",
    "    ngram = []\n",
    "    _class = []\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip(\"\\n\").split(\"\\t\")\n",
    "            ngram.append(line[0])\n",
    "            _class.append(int(line[1]))\n",
    "    return pd.DataFrame({\"phrase\":ngram,\"class\":_class})\n",
    "train = loadData(\"train.tsv\")\n",
    "print(train.head())\n",
    "test = loadData(\"test.tsv\")    \n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NMt0FeRhOsK"
   },
   "source": [
    "## load word2vec model\n",
    "<font color=\"red\">**[ TODO ]**</font> Please load [GoogleNews-vectors-negative300.bin.gz](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g) model and check the embedding of the word `language`.\n",
    "\n",
    "* package `gensim` is a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lzp9-HTwhOsK"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "w2v_model = KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0SOXJr4hOsL",
    "outputId": "9b98668d-c493-4b7b-a722-4de375b2f9d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.30712891e-02  1.68457031e-02  1.54296875e-01  1.27929688e-01\n",
      " -2.67578125e-01  3.51562500e-02  1.19140625e-01  2.48046875e-01\n",
      "  1.93359375e-01 -7.95898438e-02  1.46484375e-01 -1.43554688e-01\n",
      " -3.04687500e-01  3.46679688e-02 -1.85546875e-02  1.06933594e-01\n",
      " -1.52343750e-01  2.89062500e-01  2.35595703e-02 -3.80859375e-01\n",
      "  1.09863281e-01  4.41406250e-01  3.75976562e-02 -1.22680664e-02\n",
      "  1.62353516e-02 -2.24609375e-01  7.61718750e-02 -3.12500000e-02\n",
      " -2.16064453e-02  1.49414062e-01 -4.02832031e-02 -4.46777344e-02\n",
      " -1.72851562e-01  3.32031250e-02  1.50390625e-01 -5.05371094e-02\n",
      "  2.72216797e-02  3.00781250e-01 -1.33789062e-01 -7.56835938e-02\n",
      "  1.93359375e-01 -1.98242188e-01 -1.27563477e-02  4.19921875e-01\n",
      " -2.19726562e-01  1.44531250e-01 -3.93066406e-02  1.94335938e-01\n",
      " -3.12500000e-01  1.84570312e-01  1.48773193e-04 -1.67968750e-01\n",
      " -7.37304688e-02 -3.12500000e-02  1.57226562e-01  3.30078125e-01\n",
      " -1.42578125e-01 -3.16406250e-01 -7.32421875e-02 -5.76171875e-02\n",
      "  1.02050781e-01 -1.08886719e-01  1.24023438e-01 -2.50244141e-02\n",
      " -2.49023438e-01  1.25976562e-01 -1.79687500e-01  3.32031250e-01\n",
      "  7.14111328e-03  2.51953125e-01  4.34570312e-02 -4.34570312e-02\n",
      " -3.90625000e-01  1.76757812e-01 -1.13525391e-02 -1.97753906e-02\n",
      "  2.79296875e-01  2.36328125e-01  1.19140625e-01  5.59082031e-02\n",
      "  1.73828125e-01 -1.10839844e-01 -4.95605469e-02  2.13867188e-01\n",
      "  6.17675781e-02  1.38671875e-01 -4.45556641e-03  2.55859375e-01\n",
      "  1.80664062e-01  5.88378906e-02 -6.59179688e-02 -2.08007812e-01\n",
      " -1.19140625e-01 -1.57226562e-01  5.02929688e-02 -6.29882812e-02\n",
      "  5.00488281e-02 -7.27539062e-02  1.74560547e-02 -3.56445312e-02\n",
      " -1.93359375e-01  3.93066406e-02 -3.36914062e-02 -1.07421875e-01\n",
      "  5.78613281e-02 -8.20312500e-02  1.74560547e-02 -1.65039062e-01\n",
      "  1.46484375e-01 -3.08837891e-02 -3.86718750e-01  2.49023438e-01\n",
      "  8.74023438e-02 -2.15820312e-01 -4.10156250e-02  1.60156250e-01\n",
      "  1.85546875e-01 -2.27050781e-02 -3.73535156e-02  7.86132812e-02\n",
      " -1.46484375e-01  6.78710938e-02  1.26953125e-01  3.30078125e-01\n",
      "  1.11328125e-01  9.27734375e-02 -3.45703125e-01 -1.41601562e-01\n",
      " -5.29785156e-02 -1.50390625e-01 -7.81250000e-02 -1.27929688e-01\n",
      " -4.02343750e-01 -1.41601562e-01  8.44726562e-02  1.08398438e-01\n",
      " -4.44335938e-02  3.73535156e-02  5.61523438e-02 -1.91406250e-01\n",
      "  1.54296875e-01 -5.12695312e-02 -6.49414062e-02 -8.30078125e-02\n",
      "  7.17773438e-02 -1.33789062e-01  1.05468750e-01  3.33984375e-01\n",
      " -1.08398438e-01  1.91650391e-02  2.14843750e-01  2.15820312e-01\n",
      " -1.05468750e-01 -1.44531250e-01  4.32128906e-02 -2.71484375e-01\n",
      " -3.78906250e-01  1.09863281e-01 -8.15429688e-02 -6.12792969e-02\n",
      " -1.33789062e-01  9.71679688e-02 -1.04370117e-02 -1.21093750e-01\n",
      " -2.44140625e-01  1.02050781e-01  1.10839844e-01 -1.00585938e-01\n",
      "  1.71875000e-01 -3.61328125e-02 -4.39453125e-02  2.83203125e-01\n",
      " -8.93554688e-02 -1.70898438e-01  2.46093750e-01  1.16699219e-01\n",
      "  8.39843750e-02 -1.32812500e-01 -1.61132812e-01 -1.39648438e-01\n",
      " -8.59375000e-02 -1.37695312e-01 -9.32617188e-02 -1.33789062e-01\n",
      "  1.65039062e-01  4.93164062e-02 -1.21093750e-01 -2.11914062e-01\n",
      "  1.61132812e-01 -1.07421875e-01 -3.97949219e-02 -3.51562500e-01\n",
      " -5.02929688e-02  1.46484375e-01 -4.68750000e-02  4.17480469e-02\n",
      " -1.27929688e-01 -9.76562500e-02 -2.46093750e-01  6.78710938e-02\n",
      " -2.30468750e-01  1.80664062e-02  3.54003906e-02  7.32421875e-02\n",
      " -2.23632812e-01 -1.25976562e-01  2.12890625e-01 -3.93066406e-02\n",
      " -2.41699219e-02 -9.61914062e-02  7.51953125e-02 -1.46484375e-01\n",
      " -1.49414062e-01 -8.83789062e-02 -4.88281250e-02  2.32421875e-01\n",
      "  3.30078125e-01  1.59179688e-01 -2.35351562e-01 -1.25976562e-01\n",
      "  2.68554688e-02 -5.29785156e-02 -6.59179688e-02 -2.17773438e-01\n",
      " -6.37817383e-03 -2.53906250e-01  2.28515625e-01  4.93164062e-02\n",
      "  3.54003906e-02  1.66992188e-01 -7.27539062e-02 -2.53906250e-01\n",
      " -1.34765625e-01  3.69140625e-01  1.83593750e-01 -1.64062500e-01\n",
      "  2.26562500e-01 -8.88671875e-02  3.69140625e-01  5.54199219e-02\n",
      " -3.63769531e-02 -1.48437500e-01  9.13085938e-02  2.47955322e-04\n",
      "  2.67578125e-01 -1.63085938e-01  1.19628906e-01  2.77343750e-01\n",
      " -1.49414062e-01  1.33789062e-01 -8.25195312e-02 -1.74804688e-01\n",
      " -1.77734375e-01  2.06054688e-01  5.07812500e-02 -2.08007812e-01\n",
      " -1.74804688e-01  9.66796875e-02  6.98242188e-02 -5.79833984e-04\n",
      "  9.22851562e-02  7.95898438e-02  1.41601562e-01  8.72802734e-03\n",
      " -8.05664062e-02  4.80957031e-02  2.49023438e-01 -1.64062500e-01\n",
      " -4.66308594e-02 -2.81250000e-01 -1.66015625e-01 -2.22656250e-01\n",
      " -2.32421875e-01  1.32812500e-01  4.15039062e-02  1.15234375e-01\n",
      " -7.66601562e-02 -1.10839844e-01 -1.97265625e-01  3.06396484e-02\n",
      " -1.03515625e-01  2.49023438e-02 -2.52685547e-02  3.39355469e-02\n",
      "  4.29687500e-02 -1.44531250e-01  2.12402344e-02  2.28271484e-02\n",
      " -1.88476562e-01  3.22265625e-01 -1.13281250e-01 -7.61718750e-02\n",
      "  2.94921875e-01 -1.33789062e-01 -1.80664062e-02 -6.25610352e-03\n",
      " -1.62353516e-02  5.98144531e-02  1.21582031e-01  4.17480469e-02]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model['language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSd3tepJhOsM"
   },
   "source": [
    "<font color=\"green\">Expected output: </font>\n",
    "\n",
    ">  <font face='monospace' size=3>\\[&nbsp;2.30712891e-02&nbsp;&nbsp;1.68457031e-02&nbsp;&nbsp;1.54296875e-01&nbsp; 1.27929688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.67578125e-01&nbsp;&nbsp;3.51562500e-02&nbsp;&nbsp;1.19140625e-01&nbsp; 2.48046875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.93359375e-01&nbsp;-7.95898438e-02&nbsp;&nbsp;1.46484375e-01&nbsp;-1.43554688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.04687500e-01&nbsp;&nbsp;3.46679688e-02&nbsp;-1.85546875e-02&nbsp; 1.06933594e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.52343750e-01&nbsp;&nbsp;2.89062500e-01&nbsp;&nbsp;2.35595703e-02&nbsp;-3.80859375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.09863281e-01&nbsp;&nbsp;4.41406250e-01&nbsp;&nbsp;3.75976562e-02&nbsp;-1.22680664e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.62353516e-02&nbsp;-2.24609375e-01&nbsp;&nbsp;7.61718750e-02&nbsp;-3.12500000e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.16064453e-02&nbsp;&nbsp;1.49414062e-01&nbsp;-4.02832031e-02&nbsp;-4.46777344e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.72851562e-01&nbsp;&nbsp;3.32031250e-02&nbsp;&nbsp;1.50390625e-01&nbsp;-5.05371094e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.72216797e-02&nbsp;&nbsp;3.00781250e-01&nbsp;-1.33789062e-01&nbsp;-7.56835938e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.93359375e-01&nbsp;-1.98242188e-01&nbsp;-1.27563477e-02&nbsp; 4.19921875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.19726562e-01&nbsp;&nbsp;1.44531250e-01&nbsp;-3.93066406e-02&nbsp; 1.94335938e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.12500000e-01&nbsp;&nbsp;1.84570312e-01&nbsp;&nbsp;1.48773193e-04&nbsp;-1.67968750e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-7.37304688e-02&nbsp;-3.12500000e-02&nbsp;&nbsp;1.57226562e-01&nbsp; 3.30078125e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.42578125e-01&nbsp;-3.16406250e-01&nbsp;-7.32421875e-02&nbsp;-5.76171875e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.02050781e-01&nbsp;-1.08886719e-01&nbsp;&nbsp;1.24023438e-01&nbsp;-2.50244141e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.49023438e-01&nbsp;&nbsp;1.25976562e-01&nbsp;-1.79687500e-01&nbsp; 3.32031250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;7.14111328e-03&nbsp;&nbsp;2.51953125e-01&nbsp;&nbsp;4.34570312e-02&nbsp;-4.34570312e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.90625000e-01&nbsp;&nbsp;1.76757812e-01&nbsp;-1.13525391e-02&nbsp;-1.97753906e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.79296875e-01&nbsp;&nbsp;2.36328125e-01&nbsp;&nbsp;1.19140625e-01&nbsp; 5.59082031e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.73828125e-01&nbsp;-1.10839844e-01&nbsp;-4.95605469e-02&nbsp; 2.13867188e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;6.17675781e-02&nbsp;&nbsp;1.38671875e-01&nbsp;-4.45556641e-03&nbsp; 2.55859375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.80664062e-01&nbsp;&nbsp;5.88378906e-02&nbsp;-6.59179688e-02&nbsp;-2.08007812e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.19140625e-01&nbsp;-1.57226562e-01&nbsp;&nbsp;5.02929688e-02&nbsp;-6.29882812e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;5.00488281e-02&nbsp;-7.27539062e-02&nbsp;&nbsp;1.74560547e-02&nbsp;-3.56445312e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.93359375e-01&nbsp;&nbsp;3.93066406e-02&nbsp;-3.36914062e-02&nbsp;-1.07421875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;5.78613281e-02&nbsp;-8.20312500e-02&nbsp;&nbsp;1.74560547e-02&nbsp;-1.65039062e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.46484375e-01&nbsp;-3.08837891e-02&nbsp;-3.86718750e-01&nbsp; 2.49023438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;8.74023438e-02&nbsp;-2.15820312e-01&nbsp;-4.10156250e-02&nbsp; 1.60156250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.85546875e-01&nbsp;-2.27050781e-02&nbsp;-3.73535156e-02&nbsp; 7.86132812e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.46484375e-01&nbsp;&nbsp;6.78710938e-02&nbsp;&nbsp;1.26953125e-01&nbsp; 3.30078125e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.11328125e-01&nbsp;&nbsp;9.27734375e-02&nbsp;-3.45703125e-01&nbsp;-1.41601562e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-5.29785156e-02&nbsp;-1.50390625e-01&nbsp;-7.81250000e-02&nbsp;-1.27929688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-4.02343750e-01&nbsp;-1.41601562e-01&nbsp;&nbsp;8.44726562e-02&nbsp; 1.08398438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-4.44335938e-02&nbsp;&nbsp;3.73535156e-02&nbsp;&nbsp;5.61523438e-02&nbsp;-1.91406250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.54296875e-01&nbsp;-5.12695312e-02&nbsp;-6.49414062e-02&nbsp;-8.30078125e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;7.17773438e-02&nbsp;-1.33789062e-01&nbsp;&nbsp;1.05468750e-01&nbsp; 3.33984375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.08398438e-01&nbsp;&nbsp;1.91650391e-02&nbsp;&nbsp;2.14843750e-01&nbsp; 2.15820312e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.05468750e-01&nbsp;-1.44531250e-01&nbsp;&nbsp;4.32128906e-02&nbsp;-2.71484375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.78906250e-01&nbsp;&nbsp;1.09863281e-01&nbsp;-8.15429688e-02&nbsp;-6.12792969e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.33789062e-01&nbsp;&nbsp;9.71679688e-02&nbsp;-1.04370117e-02&nbsp;-1.21093750e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.44140625e-01&nbsp;&nbsp;1.02050781e-01&nbsp;&nbsp;1.10839844e-01&nbsp;-1.00585938e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.71875000e-01&nbsp;-3.61328125e-02&nbsp;-4.39453125e-02&nbsp; 2.83203125e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-8.93554688e-02&nbsp;-1.70898438e-01&nbsp;&nbsp;2.46093750e-01&nbsp; 1.16699219e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;8.39843750e-02&nbsp;-1.32812500e-01&nbsp;-1.61132812e-01&nbsp;-1.39648438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-8.59375000e-02&nbsp;-1.37695312e-01&nbsp;-9.32617188e-02&nbsp;-1.33789062e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.65039062e-01&nbsp;&nbsp;4.93164062e-02&nbsp;-1.21093750e-01&nbsp;-2.11914062e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.61132812e-01&nbsp;-1.07421875e-01&nbsp;-3.97949219e-02&nbsp;-3.51562500e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-5.02929688e-02&nbsp;&nbsp;1.46484375e-01&nbsp;-4.68750000e-02&nbsp; 4.17480469e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.27929688e-01&nbsp;-9.76562500e-02&nbsp;-2.46093750e-01&nbsp; 6.78710938e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.30468750e-01&nbsp;&nbsp;1.80664062e-02&nbsp;&nbsp;3.54003906e-02&nbsp; 7.32421875e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.23632812e-01&nbsp;-1.25976562e-01&nbsp;&nbsp;2.12890625e-01&nbsp;-3.93066406e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.41699219e-02&nbsp;-9.61914062e-02&nbsp;&nbsp;7.51953125e-02&nbsp;-1.46484375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.49414062e-01&nbsp;-8.83789062e-02&nbsp;-4.88281250e-02&nbsp; 2.32421875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;3.30078125e-01&nbsp;&nbsp;1.59179688e-01&nbsp;-2.35351562e-01&nbsp;-1.25976562e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.68554688e-02&nbsp;-5.29785156e-02&nbsp;-6.59179688e-02&nbsp;-2.17773438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-6.37817383e-03&nbsp;-2.53906250e-01&nbsp;&nbsp;2.28515625e-01&nbsp; 4.93164062e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;3.54003906e-02&nbsp;&nbsp;1.66992188e-01&nbsp;-7.27539062e-02&nbsp;-2.53906250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.34765625e-01&nbsp;&nbsp;3.69140625e-01&nbsp;&nbsp;1.83593750e-01&nbsp;-1.64062500e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.26562500e-01&nbsp;-8.88671875e-02&nbsp;&nbsp;3.69140625e-01&nbsp; 5.54199219e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.63769531e-02&nbsp;-1.48437500e-01&nbsp;&nbsp;9.13085938e-02&nbsp; 2.47955322e-04<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.67578125e-01&nbsp;-1.63085938e-01&nbsp;&nbsp;1.19628906e-01&nbsp; 2.77343750e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.49414062e-01&nbsp;&nbsp;1.33789062e-01&nbsp;-8.25195312e-02&nbsp;-1.74804688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.77734375e-01&nbsp;&nbsp;2.06054688e-01&nbsp;&nbsp;5.07812500e-02&nbsp;-2.08007812e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.74804688e-01&nbsp;&nbsp;9.66796875e-02&nbsp;&nbsp;6.98242188e-02&nbsp;-5.79833984e-04<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;9.22851562e-02&nbsp;&nbsp;7.95898438e-02&nbsp;&nbsp;1.41601562e-01&nbsp; 8.72802734e-03<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-8.05664062e-02&nbsp;&nbsp;4.80957031e-02&nbsp;&nbsp;2.49023438e-01&nbsp;-1.64062500e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-4.66308594e-02&nbsp;-2.81250000e-01&nbsp;-1.66015625e-01&nbsp;-2.22656250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.32421875e-01&nbsp;&nbsp;1.32812500e-01&nbsp;&nbsp;4.15039062e-02&nbsp; 1.15234375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-7.66601562e-02&nbsp;-1.10839844e-01&nbsp;-1.97265625e-01&nbsp; 3.06396484e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.03515625e-01&nbsp;&nbsp;2.49023438e-02&nbsp;-2.52685547e-02&nbsp; 3.39355469e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;4.29687500e-02&nbsp;-1.44531250e-01&nbsp;&nbsp;2.12402344e-02&nbsp; 2.28271484e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.88476562e-01&nbsp;&nbsp;3.22265625e-01&nbsp;-1.13281250e-01&nbsp;-7.61718750e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.94921875e-01&nbsp;-1.33789062e-01&nbsp;-1.80664062e-02&nbsp;-6.25610352e-03<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.62353516e-02&nbsp;&nbsp;5.98144531e-02&nbsp;&nbsp;1.21582031e-01&nbsp; 4.17480469e-02\\] </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkLkJINzhOsR"
   },
   "source": [
    "## Preprocessing\n",
    "Preprocess two tsv files here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVPtIXn1hOsS"
   },
   "source": [
    "#### adjust the ratio of the two classes of training data\n",
    "In training data, the ratio of good phrases to bad phrases is about one to thirty. That will make training classification unsatisfactory, so we need to adjust the ratio. Reducing bad phrases and adding good phrases are both common way.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Please adjust the ratio of good phrases to bad phrases in any way which you think is the best and output the number of two class for demo.\n",
    "\n",
    "You need to explain why you choose this ratio and how you do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nSnoSUkhOsS",
    "outputId": "ffd5744c-79e4-41f6-fa98-c52811fcc781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target statistics: Counter({0: 193493, 1: 6105})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(f\"Training target statistics: {Counter(train['class'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p37zgcSzhOsU"
   },
   "source": [
    "#### number words\n",
    "Let each word have its unique number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "evUrShgDhOsU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(pd.concat([train,test],ignore_index=True)['phrase'])\n",
    "vocab_size = len(tok.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5rsL01lhOsU"
   },
   "source": [
    "#### convert phrases into numbers\n",
    "Because model can't read words, so we have to do this transform. \n",
    "\n",
    "The number should be same as the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jlkO5YSIhOsU"
   },
   "outputs": [],
   "source": [
    "train_encoded_phrase = tok.texts_to_sequences(train['phrase'])\n",
    "test_encoded_phrase = tok.texts_to_sequences(test['phrase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MeBObTDhOsV"
   },
   "source": [
    "#### padding\n",
    "Make all phrases become same length. The longest phrases in two tsv have five tokens. Hence, we should make the phrases whose lengths less than five become five by adding 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRZWt221hOsV",
    "outputId": "30a40ce3-997b-4b24-bdd5-760da31c4c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    3 1970  253    0]\n",
      " [7468   10 1971    1  122]\n",
      " [   2    1  119    0    0]\n",
      " [   2    1   43   64    0]\n",
      " [  23    1 1760 1507    0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_ngram = 5\n",
    "X_train= pad_sequences(train_encoded_phrase, maxlen=max_ngram, padding='post')\n",
    "X_test= pad_sequences(test_encoded_phrase, maxlen=max_ngram, padding='post')\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0n8J5othOsV"
   },
   "source": [
    "#### one hot encodding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qdSuIFyjhOsV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train=to_categorical(train['class'])\n",
    "y_test=to_categorical(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caMqkjEShOsW",
    "outputId": "4fa9fde7-919a-48f8-bb18-7ec5ac666258",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 193493) (1, 193493)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "x_res, y_res = over_sampler.fit_resample(X_train, y_train )\n",
    "unique, counts = numpy.unique(y_res, return_counts=True)\n",
    "print(*zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3srGjE49hOsW"
   },
   "source": [
    "#### split training data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "m5UpKIEjhOsW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(x_res,y_res,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ri8iX3ThOsW"
   },
   "source": [
    "#### creating the embedding matrix\n",
    "The embedding matrix is used by classification model. It should be a list of list. Each sub-list is an embedding vector of a word and the order of all embedding vectors should be same as *tokenizer*. It is stored in a dictionary. You can check it by `tok.word_index.items()`.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Make embedding matrix. If you don't need it for your classification model, you can skip it. We won't check it when demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXRmK-LJI4-R",
    "outputId": "11cc0e82-045d-4c63-c8f0-29255255a0e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7446\n",
      "1702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.02416992, -0.12695312, -0.359375  , ..., -0.203125  ,\n",
       "         0.23828125, -0.15332031],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.16796875, -0.07373047, -0.24707031, ...,  0.03613281,\n",
       "        -0.02661133,  0.0324707 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = vocab_size\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = numpy.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tok.word_index.items():\n",
    "    if word in w2v_model:\n",
    "        embedding_matrix[i] = w2v_model[word]\n",
    "        hits+=1\n",
    "    else:\n",
    "        misses+=1 \n",
    "print(hits)\n",
    "print(misses)     \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiPPidI2hOsX"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CAEYNCOhOsX"
   },
   "source": [
    "#### build model\n",
    "<font color=\"red\">**[ TODO ]**</font> Please build your classification model by ***keras*** here. \n",
    "\n",
    "You **must** use the pre-trained word2vec model to represent the words of phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "iBrGtQoPhOsX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "xl6hXoXQhOsX"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim , embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                    trainable=False, input_length=X_train.shape[1]))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jtccsophOsX",
    "outputId": "4e1dbddb-a38a-4073-bc8c-a3dc45c87c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5, 300)            2744700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,787,390\n",
      "Trainable params: 42,690\n",
      "Non-trainable params: 2,744,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDNT4_4ohOsX"
   },
   "source": [
    "#### train\n",
    "Train classification model here.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Adjust the hyperparameter to optimize the validation accuracy and validation loss.\n",
    "\n",
    "* The higher the accuracy, the better; the lower the validation, the better.\n",
    "* **number of epoch** and **batch size** are the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mM80D00jhOsX",
    "outputId": "fa02f5ce-f96c-4c1e-9a27-1b3573d676d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9675/9675 [==============================] - 43s 4ms/step - loss: 0.0807 - accuracy: 0.9755 - val_loss: 0.0504 - val_accuracy: 0.9873\n",
      "Epoch 2/5\n",
      "9675/9675 [==============================] - 41s 4ms/step - loss: 0.0489 - accuracy: 0.9878 - val_loss: 0.0468 - val_accuracy: 0.9889\n",
      "Epoch 3/5\n",
      "9675/9675 [==============================] - 41s 4ms/step - loss: 0.0458 - accuracy: 0.9885 - val_loss: 0.0458 - val_accuracy: 0.9887\n",
      "Epoch 4/5\n",
      "9675/9675 [==============================] - 41s 4ms/step - loss: 0.0439 - accuracy: 0.9887 - val_loss: 0.0434 - val_accuracy: 0.9892\n",
      "Epoch 5/5\n",
      "9675/9675 [==============================] - 41s 4ms/step - loss: 0.0426 - accuracy: 0.9889 - val_loss: 0.0439 - val_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c5ba83490>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYsIhp4fhOsX"
   },
   "source": [
    "#### test\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Test your model by test.tsv and output the accuracy. Your accuracy need to beat baseline: **0.97**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0cGx8IxhOsY",
    "outputId": "9018deaa-b55d-4b1a-d81f-b18e3103d4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 2ms/step - loss: 0.0552 - accuracy: 0.9850\n",
      "0.9850000143051147\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, numpy.argmax(y_test,axis=1))\n",
    "print(accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9ARODTChOsY"
   },
   "source": [
    "## Show wrong prediction results\n",
    "Observing wrong prediction result may help you improve your prediction.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> show the wrong prediction results like this: \n",
    "\n",
    "<img src=\"https://imgur.com/BOTMyZH.jpg\" width=30%><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLCdBayDhOsY",
    "outputId": "25806da0-0317-4f6e-f0bf-9aca41b51f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram                          label predict\n",
      "earn a playoff berth           0     1    \n",
      "- earn - money -               1     0    \n",
      "earn the money ?               1     0    \n",
      "earn your Masters Degree       1     0    \n",
      "earn their money ;             1     0    \n",
      "earn 1 comp point              0     1    \n",
      "earn a roster spot             0     1    \n",
      "earn a very good livelihood    1     0    \n",
      "earn your commission !         1     0    \n",
      "earn victory                   0     1    \n",
      "- earn affiliate income        1     0    \n",
      "more you earn . \"              1     0    \n",
      "earn commission                0     1    \n",
      "] \" earn money                 1     0    \n",
      "earn a standard diploma        0     1    \n",
      "what they can earn ,           1     0    \n",
      "earn residual income           0     1    \n",
      ", earn on average              1     0    \n",
      "Family Meeting can earn        0     1    \n",
      ", earn or get money            1     0    \n",
      "earn an NCAA berth             0     1    \n",
      "what I earn ,                  1     0    \n",
      "earn an income                 0     1    \n",
      "earn a salary to               1     0    \n",
      "earn Free Gear with Bonus      1     0    \n",
      "earn a playoff spot            0     1    \n",
      "point inspection to earn       0     1    \n",
      "earn the Most                  0     1    \n",
      "earn them \"                    1     0    \n",
      "- money earn -                 1     0    \n"
     ]
    }
   ],
   "source": [
    "print(\"{:<30} {:<5} {:<5}\".format(\"ngram\",\"label\",\"predict\"))\n",
    "for i in range(len(X_test)):\n",
    "    prediction = model.predict(numpy.expand_dims(X_test[i], axis=0))\n",
    "    prediction_num = numpy.argmax(prediction)\n",
    "    if prediction_num != numpy.argmax(y_test[i]):\n",
    "        print(\"{:<30} {:<5} {:<5}\".format(test['phrase'][i],prediction_num,numpy.argmax(y_test[i]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldyy92wUhOsY"
   },
   "source": [
    "## TA's Notes\n",
    "\n",
    "If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1QGeYl5dsD9sFO9SYg4DIKk-xr-yGjRDOOLKZqCLDv2E/edit#gid=807282025) to reserve demo time.  \n",
    "The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to eeclass. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n",
    "<br>Note that **late submission will not be allowed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeytX8n5hOsY"
   },
   "source": [
    "## Learning Resource\n",
    "[Deep Learning with Python](https://tanthiamhuat.files.wordpress.com/2018/03/deeplearningwithpython.pdf)\n",
    "\n",
    "[Classification on IMDB](https://keras.io/examples/nlp/bidirectional_lstm_imdb/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
