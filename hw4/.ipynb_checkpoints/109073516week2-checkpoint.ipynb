{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment02: Find Academic Keyword List\n",
    "Academic Keywords are the words we seldom use ordinarily, but often use in Academic articles. \"This shows\" and \"in conclusion\" are examples of Academic Keywords. This assignment want you to use Rank Ratio and compare two dataset to find Academic Keyword List(AKL).\n",
    "<br><br>\n",
    "One dataset is taken from [`British Academic Written English Corpus(BAWE)`](https://www.coventry.ac.uk/research/research-directories/current-projects/2015/british-academic-written-english-corpus-bawe/), which collect a record of proficient university-level student writing. Hence, BAWE can be seen as Academic data. Another one is called [`Web1T`](https://catalog.ldc.upenn.edu/LDC2006T13), which is presented by Google. Web1T colloct 1 trillion words of English Web, so we can treat it as the representative of common words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram counting\n",
    "This part is almost same as what you need to do in Assignment01. The way to find N-gram is the same as Assignment01. However, tokenization and calculating frequency are a little different. The rules of tokenization in this Assignment are:\n",
    " 1. Ignore case (e.g., \"The\" is the same as \"the\")\n",
    " 2. Split by white spaces <s>and punctuations</s>\n",
    " 3. Ignore all punctuation\n",
    "<br><br>\n",
    "\n",
    "As for calculating frequency, we want you calculating <u>document frequency</u> in this Assignment. <br>What is document frequency? \n",
    "<br>Article 1: \n",
    "> We all know that water masses in the ocean are thought to be transferred by the wind. ...\n",
    "\n",
    "Althought there are at least 2 \"the\" in Article 1, the document frequency of \"the\" is still 1 in this article.<br> No mater how many times does \"the\" show up in Article 1, the document frquency of it is always 1.<br>\n",
    "Article 2: \n",
    "> The film Dantes Peak is about a dormant volcano that suddenly erupts and threatens the nearby town. ...\n",
    "\n",
    "Considering the Article 1 and 2, the document frequency of \"the\" is 2 now.<br>\n",
    "Document frequency can reduce the influence of terms, like \"NLP\".\n",
    "<br><br>\n",
    "<span style=\"color: red\">[ TODO ]</span> Try to modify the functions coded in Assignment01 to <u>calculate document frequencies of all unigram.</u>.\n",
    "\n",
    "Google has calculated the frequency of N-gram, so you only need to do it on BAWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(\"[\\w']+\", text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(tokens):\n",
    "    frequency = {}\n",
    "    for item in tokens: \n",
    "        if (item in frequency): \n",
    "            frequency[item] += 1\n",
    "        else: \n",
    "            frequency[item] = 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(tokens, n=2):\n",
    "    grams = [tokens[i:i+n] for i in range(len(tokens)-n+1)]\n",
    "    tokens=[]\n",
    "    for i in grams:\n",
    "        str1 = \" \".join(i)\n",
    "        tokens.append(str1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('.', 'BAWE.txt')\n",
    "BAWE_unigram = []\n",
    "temp=[]\n",
    "BAWE_frequency={}\n",
    "with open(file_path, 'r' ,encoding=\"utf-8\") as f:\n",
    "    for text in f.readlines():\n",
    "        tokens = tokenize(text)\n",
    "        unigram = get_ngram(tokens, n=1)\n",
    "        unigram = calculate_frequency(unigram)\n",
    "        temp.append(unigram)\n",
    "    for article in temp:\n",
    "        for key in article:\n",
    "    #for i in range(len(temp)):\n",
    "        #for key in temp[i]:\n",
    "            if (key in BAWE_frequency): \n",
    "                BAWE_frequency[key] += 1\n",
    "            else: \n",
    "                BAWE_frequency[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Web1T Data\n",
    "file_path = os.path.join('.', 'Web1T_unigram.txt')\n",
    "Web1T_unigram_counter = {}\n",
    "with open(file_path,'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        Web1T_unigram_counter[line[0]] = int(line[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank\n",
    "Rank unigrms by their frequencies. The higher the frequency, the higher the rank.(The most frequent unigram ranks 1.)<br>\n",
    "<span style=\"color: red\">[ TODO ]</span> <u>Rank unigrams for Web1T and BAWE.</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Web1T_unigram_rank =dict(sorted(Web1T_unigram_counter.items(), key=lambda x:x[1],reverse=True))\n",
    "cnt = 0\n",
    "for key, value in Web1T_unigram_rank.items():\n",
    "    cnt += 1\n",
    "    Web1T_unigram_rank[key] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAWE_unigram_rank=dict(sorted(BAWE_frequency.items(), key=lambda x:x[1],reverse=True))\n",
    "cnt = 0\n",
    "for key, value in BAWE_unigram_rank.items():\n",
    "    cnt += 1\n",
    "    BAWE_unigram_rank[key] = cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rank Ratio\n",
    "In this step, you need to map the same unigram in two dataset, and caalculate the Rank Ratio of unigram in BAWE.  <br>Please follow the formula for calculating Rank Ratio:<br> \n",
    "<br>\n",
    "<img src=\"https://imgur.com/vmK7Q1K.jpg\" width=30%><br>\n",
    "If the unigram doesn't appear in Web1T, the rank of it is treated as 1.\n",
    "\n",
    "<span style=\"color: red\">[ TODO ]</span> Please calculate all rank ratios of unigrams in BAWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [TODO] calculate all rank ratios of unigrams in BAWE\n",
    "rank_ratios={}\n",
    "for i in BAWE_unigram_rank:\n",
    "    if i in Web1T_unigram_rank:\n",
    "        rank_ratios[i] = Web1T_unigram_rank[i]/BAWE_unigram_rank[i]\n",
    "    else:\n",
    "        rank_ratios[i]= 1/BAWE_unigram_rank[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort the result\n",
    "<span style=\"color: red\">[ TODO ]</span> Please show top 30 uigrams in Rank Ratio and the value of their Rank Ratio in this format: \n",
    "<br>\n",
    "<img src=\"https://imgur.com/AEkiCRr.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [ TODO ] souw the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_n(rank_ratios: dict, n=10):\n",
    "    rank_ratios = dict(sorted(rank_ratios.items(), key=lambda x: x[1],reverse = True))\n",
    "    print(\"{:<4} {:<20} {:<10}\".format(\"rank\",\"unigram\",\"Rank Ratio\"))\n",
    "    for key, value in list(rank_ratios.items())[:n]:\n",
    "            print(\"{:<4} {:<20} {:<10}\".format(list(rank_ratios.keys()).index(key)+1,key,round(value, 3)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank unigram              Rank Ratio\n",
      "1    cannot               585.687   \n",
      "2    firstly              27.729    \n",
      "3    conclusion           26.214    \n",
      "4    trudgill             21.776    \n",
      "5    gleitman             21.014    \n",
      "6    sibilance            20.058    \n",
      "7    generalisability     19.273    \n",
      "8    therefore            19.162    \n",
      "9    cyanosis             18.435    \n",
      "10   legitimising         18.156    \n",
      "11   foregrounded         17.965    \n",
      "12   plosives             17.964    \n",
      "13   assonance            17.211    \n",
      "14   emphasises           16.781    \n",
      "15   debateable           16.76     \n",
      "16   stoppered            16.557    \n",
      "17   lymphadenopathy      16.337    \n",
      "18   craib                16.333    \n",
      "19   hypothesise          16.325    \n",
      "20   pasteurised          16.225    \n",
      "21   colonisers           16.163    \n",
      "22   hypothesised         16.013    \n",
      "23   pyrexia              15.999    \n",
      "24   behaviourally        15.906    \n",
      "25   pipetted             15.892    \n",
      "26   dyspnoea             15.802    \n",
      "27   behaviourist         15.793    \n",
      "28   quantised            15.021    \n",
      "29   jarque               14.949    \n",
      "30   homogenised          14.784    \n"
     ]
    }
   ],
   "source": [
    "print_top_n(rank_ratios, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Bigrams\n",
    "<span style=\"color: red\">[ TODO ]</span> Do the Same Thing for Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('.', 'BAWE.txt')\n",
    "BAWE_bigram = []\n",
    "temp=[]\n",
    "BAWE_frequency={}\n",
    "with open(file_path, 'r' ,encoding=\"utf-8\") as f:\n",
    "    for text in f.readlines():\n",
    "        tokens = tokenize(text)\n",
    "        bigram = get_ngram(tokens, n=2)\n",
    "        bigram = calculate_frequency(bigram)\n",
    "        temp.append(bigram)\n",
    "    for article in temp:\n",
    "        for key in article:\n",
    "            if (key in BAWE_frequency): \n",
    "                BAWE_frequency[key] += 1\n",
    "            else: \n",
    "                BAWE_frequency[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [TODO]\n",
    "# Read Web1T Data\n",
    "file_path = os.path.join('.', 'Web1T_bigram.txt')\n",
    "Web1T_bigram_counter = {}\n",
    "with open(file_path, 'r' ,encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        Web1T_bigram_counter[line[0]] = int(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web1T_bigram_rank =dict(sorted(Web1T_bigram_counter.items(), key=lambda x:x[1],reverse=True))\n",
    "cnt = 0\n",
    "for key, value in Web1T_bigram_rank.items():\n",
    "    cnt += 1\n",
    "    Web1T_bigram_rank[key] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAWE_bigram_rank=dict(sorted(BAWE_frequency.items(), key=lambda x:x[1],reverse=True))\n",
    "cnt = 0\n",
    "for key, value in BAWE_bigram_rank.items():\n",
    "    cnt += 1\n",
    "    BAWE_bigram_rank[key] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigrams_rank_ratios={}\n",
    "for i in BAWE_bigram_rank:\n",
    "    if i in Web1T_bigram_rank:\n",
    "        Bigrams_rank_ratios[i] = Web1T_bigram_rank[i]/BAWE_bigram_rank[i]\n",
    "    else:\n",
    "        Bigrams_rank_ratios[i]= 1/BAWE_bigram_rank[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank unigram              Rank Ratio\n",
      "1    in conclusion        507.846   \n",
      "2    however this         418.716   \n",
      "3    however the          372.571   \n",
      "4    however in           284.07    \n",
      "5    however it           248.514   \n",
      "6    this essay           228.844   \n",
      "7    however there        218.755   \n",
      "8    the british          182.986   \n",
      "9    the european         154.683   \n",
      "10   this suggests        138.558   \n",
      "11   this shows           106.637   \n",
      "12   see appendix         92.282    \n",
      "13   analysis the         90.35     \n",
      "14   therefore it         89.858    \n",
      "15   however a            89.174    \n",
      "16   therefore the        86.014    \n",
      "17   method the           76.249    \n",
      "18   conclusion in        64.551    \n",
      "19   however he           61.932    \n",
      "20   the united           61.098    \n",
      "21   the uk               60.392    \n",
      "22   however to           59.88     \n",
      "23   c the                59.015    \n",
      "24   system the           58.866    \n",
      "25   therefore this       58.687    \n",
      "26   despite this         57.154    \n",
      "27   i shall              57.091    \n",
      "28   example it           57.047    \n",
      "29   in england           55.97     \n",
      "30   in appendix          55.64     \n"
     ]
    }
   ],
   "source": [
    "print_top_n(Bigrams_rank_ratios, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bonus question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('.', 'AKL.txt')\n",
    "with open(file_path,'r') as f:\n",
    "    for text in f.readlines():\n",
    "        tokens = tokenize(text)\n",
    "        unigram = get_ngram(tokens, n=1)\n",
    "        unigram = calculate_frequency(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word       Rank Ratio    is in AKL \n",
      "question   2.201         yes       \n",
      "answer     1.352         no        \n",
      "area       1.063         no        \n",
      "active     0.974         yes       \n",
      "research   0.671         yes       \n"
     ]
    }
   ],
   "source": [
    "word=['question','answer','area','active','research']\n",
    "print(\"{:<10} {:<13} {:<10}\".format(\"word\",\"Rank Ratio\",\"is in AKL\"))\n",
    "for i in word:\n",
    "    if i in unigram:\n",
    "        print(\"{:<10} {:<13} {:<10}\".format(i,round(rank_ratios[i],3),'yes'))\n",
    "    else:\n",
    "        print(\"{:<10} {:<13} {:<10}\".format(i,round(rank_ratios[i],3),'no'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TA's Notes\n",
    "\n",
    "If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1QGeYl5dsD9sFO9SYg4DIKk-xr-yGjRDOOLKZqCLDv2E/edit#gid=40492256) to reserve demo time.  \n",
    "The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to eeclass. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n",
    "<br>Note that **late submission will not be allowed**.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
